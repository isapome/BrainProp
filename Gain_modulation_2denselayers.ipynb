{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gain_modulation_2denselayers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isapome/BrainProp/blob/master/Gain_modulation_2denselayers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxHB1Az0Bsut"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0tKH_rzBu6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18295435-5a36-43bf-b106-45aa02a68a2c"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-87bd67be-9af1-ce83-ac58-9a9caf3bfebe)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ0_HcqrBwnf"
      },
      "source": [
        "# Abstract layer class, do not initialize\n",
        "class Layer:\n",
        "    def __init__(self, shape_in, shape_out, s, w_std=0.02, activation=tf.identity, dropout_rate=0., flatten=False):\n",
        "        # Arguments:\n",
        "          # shape_in, shape_out := lists containing dimensions of layer input and output\n",
        "          # s, w_std := weight initialization seed (integer) and standard deviation (float)\n",
        "        if isinstance(shape_in, list):\n",
        "          self.shape_in = shape_in\n",
        "        else:\n",
        "          self.shape_in = list(shape_in)\n",
        "        self.shape_out = shape_out\n",
        "\n",
        "        # Weights are sampled from a normal distribution, bias and attentional gain are initialized to 0\n",
        "        self.ff_weights = tf.Variable(tf.random.normal(self.get_weights(), stddev=w_std, seed=s))\n",
        "        self.bias = tf.Variable(tf.zeros(shape_out, dtype=tf.float32))\n",
        "        self.attention = tf.Variable(tf.zeros(shape_out, dtype=tf.float64))\n",
        "\n",
        "        if flatten is True:\n",
        "          self.flatten = flatten\n",
        "        else:\n",
        "          self.flatten = np.shape(shape_in) > np.shape(shape_out)\n",
        "\n",
        "        self.activation = activation\n",
        "        self.dropout_rate, self.mask = dropout_rate, 0. #is self.mask the seed for a dropout of a forward pass? Is it the same for each layer? \n",
        "        #Does it mean that all the dropout layers will have the same mask in one go?\n",
        "        self.layer_in, self.layer_out, self.cum_input = None, None, None\n",
        "\n",
        "    # General forward pass operation to compute layer output\n",
        "    def forward_pass(self, inputs, training_phase):\n",
        "        shape_in = inputs.shape[1:]\n",
        "\n",
        "        if shape_in != self.shape_in:\n",
        "            raise Exception('Wrong input size: {}, required input: {}'.format(shape_in, self.shape_in))\n",
        "            \n",
        "        if self.flatten:\n",
        "            inputs = tf.reshape(inputs, [-1, tf.reduce_prod(shape_in)])\n",
        "\n",
        "        # Implementation in subclass (Dense, Conv, ...), returns layer-specific input\n",
        "        self.layer_in, layer_out = self.get_ff_output(inputs)\n",
        "        layer_out = tf.add(layer_out, self.bias)\n",
        "        \n",
        "        # Cumulative input, corresponds to y_in in report\n",
        "        self.cum_input = tf.cast(layer_out, tf.float64)\n",
        "        \n",
        "        # Perform operation using 64 bits to prevent rounding errors (why? makes everything slower and is it really necessary to have 15 instead of 6 precision? \n",
        "        #Then why don't you use the same in APPROX? line 37 here vs line 33 in APPROX) \n",
        "        # Rounding errors not necessary in APP\n",
        "        att_gain = tf.cast(tf.multiply(self.cum_input, self.attention), tf.float32)\n",
        "        layer_out = self.activation(tf.add(layer_out, att_gain))\n",
        "\n",
        "        if self.dropout_rate > 0 and training_phase:\n",
        "          layer_out = tf.nn.dropout(layer_out, self.dropout_rate, seed=self.mask)\n",
        "\n",
        "        self.layer_out = layer_out\n",
        "        return layer_out\n",
        "\n",
        "    # General backward pass to update attention and compute feedback\n",
        "    def backward_pass(self, prev_feedback):\n",
        "\n",
        "        # Activation function derivative over feedback\n",
        "        gated_feedback = self.feedback_gating(prev_feedback)\n",
        "\n",
        "        # Implementation in subclass, returns layer-specific feedback\n",
        "        curr_feedback = self.get_fb_output(gated_feedback)\n",
        "\n",
        "        # Compute attention update, cap attentional gain at 50%\n",
        "\n",
        "        ####is this purely for bio reasons? Different caps not tested yet. In bio 10% gain on average, 50 is a bit too large\n",
        "\n",
        "        delta_att = tf.reduce_sum(tf.multiply(tf.cast(gated_feedback, tf.float64), self.cum_input), axis=0) #how you change the betas\n",
        "        self.attention.assign(tf.clip_by_value(tf.add(self.attention, delta_att), -0.5, 0.5))\n",
        "\n",
        "        if self.flatten:\n",
        "            curr_feedback = tf.reshape(curr_feedback, [-1] + self.shape_in)\n",
        "\n",
        "        return curr_feedback\n",
        "\n",
        "    def weight_update(self, rpe):\n",
        "        attended_rpe = tf.multiply(tf.cast(rpe, tf.float64), self.attention)\n",
        "\n",
        "        # Implementation in subclass, returns weight and bias update according to HEB\n",
        "        delta_bias, delta_weights = self.get_weight_update(attended_rpe)\n",
        "\n",
        "        # Reset attention and mask\n",
        "        self.attention.assign(tf.zeros(self.shape_out, dtype=tf.float64))\n",
        "        self.mask += 1. #???????\n",
        "\n",
        "        self.bias.assign_add(delta_bias)\n",
        "        self.ff_weights.assign_add(delta_weights)\n",
        "\n",
        "    # Computes activation function derivative over feedback\n",
        "    def feedback_gating(self, feedback):\n",
        "        if self.activation == tf.nn.relu:\n",
        "            zeros = tf.zeros_like(self.layer_out)\n",
        "            return tf.where(tf.greater(self.layer_out, zeros), feedback, zeros)\n",
        "        elif self.activation == tf.nn.softmax or self.activation == tf.nn.sigmoid:  #why? in the output layer do we still update only one set of weights?\n",
        "            return tf.multiply(tf.multiply(self.layer_out, 1 - self.layer_out), feedback)\n",
        "        elif self.activation == tf.math.tanh:\n",
        "            return tf.multiply(tf.multiply(1 + self.layer_out, 1 - self.layer_out), feedback)\n",
        "        else:\n",
        "            return feedback"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rLQpijRBwuz"
      },
      "source": [
        "# Fully connected layer, see Layer descriptions\n",
        "class Dense(Layer):\n",
        "    def get_weights(self):\n",
        "        return [tf.reduce_prod(self.shape_in), self.shape_out[0]]\n",
        "\n",
        "    def get_ff_output(self, inputs):\n",
        "        return inputs, tf.matmul(inputs, self.ff_weights)\n",
        "\n",
        "    def get_fb_output(self, feedback):\n",
        "        delta_weights = self.get_weight_update(self.attention)[1]\n",
        "        new_weights = tf.add(delta_weights, self.ff_weights)\n",
        "        return tf.matmul(feedback, tf.transpose(new_weights)) #can just return new_weights and do the matmul outside:)\n",
        "    \n",
        "    def get_weight_update(self, attention):\n",
        "        norm_fb = tf.math.divide_no_nan(attention, self.cum_input)\n",
        "        norm_fb = tf.cast(norm_fb, tf.float32)\n",
        "        return tf.reduce_sum(norm_fb, axis=0), tf.matmul(tf.transpose(self.layer_in), norm_fb)\n",
        "\n",
        "# Convolutional layer\n",
        "class Conv(Layer):\n",
        "    def __init__(self, shape_in, filters, s, padding, stride, w_std=0.02, activation=tf.nn.relu, dropout_rate=0.):\n",
        "        # Arguments:\n",
        "          # shape_in, filters := lists containing dimensions of layer input and filter width, height and count\n",
        "          # s, w_std := weight initialization seed (integer) and standard deviation (float)\n",
        "          # padding := string 'VALID' or 'SAME'\n",
        "          # stride := list containing the horizonal and vertical step size\n",
        "\n",
        "        # Number of weights equals: (width filters * length filters * depth of previous layer) over the number of filters\n",
        "        self.get_weights = lambda : [int(filters[0] * filters[1] * shape_in[2]), filters[2]]\n",
        "\n",
        "        # Returns a 4-dimensional Tensor containing patches from the input layer\n",
        "        self.get_patches = lambda x: tf.image.extract_patches(x, [1, filters[0], filters[1], 1],\n",
        "                                                              [1, stride[0], stride[1], 1], [1, 1, 1, 1], padding)\n",
        "        self.get_patches_inv = None\n",
        "\n",
        "        # Initialize remaining parameters\n",
        "        n_patches = self.get_n_patches(filters[:2], padding, stride, shape_in[:2])\n",
        "        super().__init__(shape_in, n_patches + filters[-1:], s, w_std, activation, dropout_rate)\n",
        "\n",
        "    def get_n_patches(self, filters, padding, stride, shape_in):\n",
        "        if padding == 'SAME':  # the size of output is the same as the input when stride=1\n",
        "            return [int(tf.math.ceil(x / y)) for (x, y) in zip(shape_in, stride)]\n",
        "        elif padding == 'VALID':  # no padding\n",
        "            return [(x - y) // z + 1 for (x, y, z) in zip(shape_in, filters, stride)]\n",
        "        else:\n",
        "            raise Exception(\"Padding unknown\")\n",
        "\n",
        "    def get_ff_output(self, inputs):\n",
        "\n",
        "        # If different sized baches, set to -> if True:\n",
        "        if self.get_patches_inv is None: # compute inverse of get_patches\n",
        "          with tf.GradientTape(persistent=True) as t:\n",
        "              t.watch(inputs)\n",
        "              patches = self.get_patches(inputs)\n",
        "\n",
        "          # Number of patches per input node\n",
        "          num_patches = t.gradient(patches, inputs)[0]\n",
        "          self.get_patches_inv = lambda fb: t.gradient(patches, inputs, output_gradients=fb) / num_patches\n",
        "        else:\n",
        "          patches = self.get_patches(inputs)\n",
        "        return patches, tf.einsum('abcd, de -> abce', patches, self.ff_weights)\n",
        "\n",
        "    def get_fb_output(self, feedback):\n",
        "        delta_weights = self.get_weight_update(self.attention)[1]\n",
        "        new_weights = tf.add(delta_weights, self.ff_weights)\n",
        "        curr_feedback = tf.einsum('abcd, de -> abce', feedback, tf.transpose(new_weights))\n",
        "        curr_feedback = self.get_patches_inv(curr_feedback)\n",
        "        return tf.where(tf.math.is_nan(curr_feedback), tf.zeros_like(curr_feedback), curr_feedback)\n",
        "\n",
        "    def get_weight_update(self, attention):\n",
        "        norm_fb = tf.math.divide_no_nan(attention, self.cum_input)\n",
        "        norm_fb = tf.cast(norm_fb, tf.float32)\n",
        "        return tf.reduce_sum(norm_fb, axis=0), tf.einsum('abcd,abce->de', self.layer_in, norm_fb)\n",
        "\n",
        "\n",
        "# Layer initialization functions\n",
        "def conv(filters, padding, stride, w_std=0.02, activation=tf.nn.relu, dropout_rate=0.):\n",
        "    return lambda x, y: Conv(x, filters, y, padding, stride, w_std, activation, dropout_rate)\n",
        "\n",
        "def dense(size_layer, w_std=0.02, activation=tf.nn.relu, dropout_rate=0., flatten=False):\n",
        "    return lambda x, y: Dense(x, [size_layer], y, w_std, activation, dropout_rate, flatten=flatten)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAz0I-CvBws_"
      },
      "source": [
        "# Layer management class\n",
        "class Network:\n",
        "    def __init__(self, shape_in, architecture, s):\n",
        "        # Arguments:\n",
        "          # shape_in := list containing the dimensions of the input\n",
        "          # architecture := list of layer initialization functions\n",
        "          # s := weight initialization seed (integer)\n",
        "          \n",
        "        #Initialize all layers\n",
        "        ff_network = []\n",
        "        for layer in architecture:\n",
        "            new_layer = layer(shape_in, tf.random.set_seed(s))\n",
        "            ff_network.append(new_layer)\n",
        "            shape_in = ff_network[-1].shape_out\n",
        "        self.ff_network = ff_network\n",
        "        self.s = s\n",
        "\n",
        "        for i in ff_network:\n",
        "            print('Layer {}: {} -> {}, activation: {}, flatten: {}, dropout: {}%'.format(i.__class__.__name__, i.shape_in, i.shape_out, i.activation, i.flatten, i.dropout_rate))\n",
        "\n",
        "    # Define or change learning parameters\n",
        "    def compile(self, lr_weights=1e-0, lr_att=1e-2, exploration_rate=2e-2):\n",
        "        self.lr_w = lr_weights\n",
        "        self.lr_a = lr_att\n",
        "        self.exploration_rate = exploration_rate\n",
        "\n",
        "    # Fit network output to prediction using cross entropy loss over all output units\n",
        "    def fit(self, inputs, y_pred, batch_size):\n",
        "        output_network = self.forward_pass(inputs)\n",
        "        delta = tf.subtract(y_pred, output_network) \n",
        "        self.backward_pass(delta/ batch_size * self.lr_a)\n",
        "\n",
        "    # Attention-modulated Hebbian learning algorithm\n",
        "    @tf.function\n",
        "    def fit_attention(self, inputs, y_true):\n",
        "        # 1. Action-selection\n",
        "        batch_size = inputs.shape[0]\n",
        "        output_network = self.forward_pass(inputs)\n",
        "        y_pred = self.get_prediction(output_network, batch_size)\n",
        "        rpe, rewards, loss = self.get_loss(output_network, y_true, y_pred, batch_size)\n",
        "\n",
        "        # 2. Attentional phase\n",
        "        for epoch in range(attention_span):\n",
        "          self.fit(inputs, y_pred, batch_size)    \n",
        "\n",
        "        # 3. Weight update\n",
        "        for layer in self.ff_network[::-1]:\n",
        "          layer.weight_update(rpe)\n",
        "\n",
        "        return rewards, tf.math.reduce_mean(loss)\n",
        "    \n",
        "    def forward_pass(self, layer_out, trainingphase=True):\n",
        "        for layer in self.ff_network:\n",
        "            layer_out = layer.forward_pass(layer_out, trainingphase)\n",
        "        return tf.nn.softmax(layer_out, axis=-1)\n",
        "    \n",
        "    def backward_pass(self, feedback):\n",
        "        for layer in self.ff_network[::-1]:\n",
        "            feedback = layer.backward_pass(feedback)\n",
        "\n",
        "    def get_loss(self, output_network, y_true, y_pred, batch_size):\n",
        "        # Compute training accuracy\n",
        "        rewards = tf.math.count_nonzero(tf.multiply(y_true, y_pred), axis=1, dtype=tf.float32)\n",
        "\n",
        "        # Compute prediction error according to cross entropy loss derivative (HERE it probably meant SQE derivative) (NO the two derivatives are the same for both CE and SQE)\n",
        "        deltas = tf.subtract(rewards, tf.reduce_sum(tf.multiply(output_network, y_pred), axis=1))\n",
        "        deltas = tf.clip_by_value(deltas, -2, 4) / batch_size * self.lr_w\n",
        "\n",
        "        # Compute cross entropy loss\n",
        "        clipped_out = tf.clip_by_value(output_network, 1e-15, 1-1e-15)\n",
        "        loss = tf.reduce_sum(-tf.reduce_sum(y_true * tf.math.log(clipped_out), axis=-1)) #mean, in case of a minibatch?\n",
        "        # should it be loss = -zy (activation of the neuron corresponding to the correct class) + log(sumj exp(activation)j)\n",
        "        return tf.math.reduce_mean(deltas), tf.reduce_mean(rewards), loss\n",
        "\n",
        "    def get_prediction(self, output_network, batch_size):\n",
        "        argmax_vector = tf.argmax(output_network, axis=1)\n",
        "        random_vector = tf.random.uniform([batch_size], minval=0, maxval=1, seed=self.s)                                                                                                                                                                                                                      \n",
        "        multinomial_vector = tf.reshape(tf.random.categorical(output_network, 1, seed=self.s), [-1])\n",
        "        selected_classes = tf.where(tf.greater(random_vector, self.exploration_rate), argmax_vector, multinomial_vector)\n",
        "        return tf.one_hot(selected_classes, output_network.shape[1])\n",
        "\n",
        "    @tf.function\n",
        "    def evaluate(self, inputs, y_true):\n",
        "        fb_out = self.forward_pass(inputs, False)\n",
        "        equality = tf.equal(tf.argmax(fb_out, 1), tf.argmax(y_true, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
        "        return accuracy"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXHYL26YBxBH"
      },
      "source": [
        "def get_dataset(dataset, batch_size, batch_size_test):\n",
        "    print(\"Dataset: {}\".format(dataset))\n",
        "    if dataset == \"CIFAR10\":\n",
        "      from keras.datasets import cifar10\n",
        "      (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    elif dataset == \"MNIST\":\n",
        "      from keras.datasets import mnist\n",
        "      (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    else:\n",
        "      raise Exception(\"Unknown dataset\")\n",
        "    if len(np.shape(X_train)) < 4:\n",
        "      X_train = tf.expand_dims(X_train, -1).numpy()\n",
        "      X_test = tf.expand_dims(X_test, -1).numpy()\n",
        "\n",
        "    image_shape = np.shape(X_train)[1:]\n",
        "    print('Dataset size: {}'.format(len(X_train)))\n",
        "    print('Test size: {}'.format(len(X_test)))\n",
        "    # X_train = tf.divide(tf.cast(X_train, tf.float32), 255.0)\n",
        "    # X_test = tf.divide(tf.cast(X_test, tf.float32), 255.0)\n",
        "    X_train = tf.divide(tf.cast(X_train, tf.float32), 255.0)\n",
        "    X_test = tf.divide(tf.cast(X_test, tf.float32), 255.0)\n",
        "    n_classes = np.max(y_test) + 1\n",
        "    # n_classes = tf.cast(tf.reduce_max(y_test)+1, dtype=tf.int32)\n",
        "    y_train = tf.reshape(tf.one_hot(y_train, n_classes), (-1, n_classes))\n",
        "    y_test = tf.reshape(tf.one_hot(y_test, n_classes), (-1, n_classes))\n",
        "\n",
        "    train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train)).batch(batch_size)\n",
        "    test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(len(X_train)).batch(batch_size_test)\n",
        "    return train_set, test_set, image_shape, n_classes"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lgUyDKYFOwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1404a2a-6aef-4dd0-bbee-26329764583d"
      },
      "source": [
        "# Retrieve data set, define validation set\n",
        "batch_size = 1 #what happens with a bigger batch? Have you tried? Basicalyy you would have to split your network, because you have to update the betas only in one direction\n",
        "batch_size_test = 100\n",
        "train_set, test_set, input_shape, n_classes = get_dataset(\"MNIST\", batch_size, batch_size_test)\n",
        "train_set.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "n_val= 1000//batch_size #number of batches to validate on\n",
        "validation = train_set.take(n_val).unbatch().batch(batch_size_test)\n",
        "train = train_set.skip(n_val)\n",
        "\n",
        "# print(validation)\n",
        "# print(train)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: MNIST\n",
            "Dataset size: 60000\n",
            "Test size: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkMCTj5qHn1O"
      },
      "source": [
        "def train_network(attention_span, lr_a, lr_w, w_init, s):\n",
        "    print('HEB_T{}_a{}_w{}_s{}'.format(attention_span, lr_a, lr_w, s))\n",
        "\n",
        "    network_architecture = [\n",
        "        # conv(filters=[3, 3, 32], padding='VALID', stride=[1, 1], w_std=w_init),\n",
        "        # conv(filters=[3, 3, 32], padding='SAME', stride=[2, 2],  w_std=w_init, dropout_rate=0.8),\n",
        "        dense(1500,  w_std=w_init),\n",
        "        dense(1000,  w_std=w_init),\n",
        "        dense(500,  w_std=w_init),\n",
        "        dense(n_classes,  w_std=w_init, activation=tf.identity)\n",
        "    ]\n",
        "\n",
        "    network = Network(input_shape, network_architecture, s)\n",
        "    network.compile(lr_weights=lr_w, lr_att=lr_a)\n",
        "    counter=0\n",
        "\n",
        "    old_acc=0.\n",
        "    start=time.time()\n",
        "    for epoch in range(150):  #n_epochs is not passed?\n",
        "        tic = time.time()\n",
        "        loss, rewards = 0, 0\n",
        "        for (batch, (X, Y)) in enumerate(train):\n",
        "            curr_reward, curr_loss = network.fit_attention(X, Y)\n",
        "            loss+=curr_loss\n",
        "            rewards += curr_reward\n",
        "\n",
        "        avg_acc = 0.\n",
        "        # for X_test, Y_test in iter(validation):\n",
        "        for (b,(X_test, Y_test)) in enumerate(test_set):\n",
        "            # print(tf.shape(X_test))\n",
        "            curr_acc = network.evaluate(X_test, Y_test)\n",
        "            avg_acc += curr_acc\n",
        "        print('Epoch: {} Time elapsed: {:.2f}: Training loss: {:.4f} Training accuracy: {:.2f}% Validation accuracy: {:.2f}%'.format(epoch, time.time()-tic, loss/(batch+1), rewards/(batch+1) * 100, avg_acc/(b+1) * 100))\n",
        "    avg_acc = 0.\n",
        "    for (batch, (X_test, Y_test)) in enumerate(test_set):\n",
        "        curr_acc = network.evaluate(X_test, Y_test)\n",
        "        avg_acc += curr_acc\n",
        "    print('Test accuracy: {}'.format(avg_acc / (batch + 1)))\n",
        "    print('Time elapsed: {}'.format(time.time()-start))\n"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VbnomowHnkz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55b09f52-5dfb-48a1-8f88-fba6ef7e01e8"
      },
      "source": [
        "n_epochs = 150\n",
        "# input_shape = [32,32,3]\n",
        "# input_shape = [28,28,1]\n",
        "# n_classes = 10\n",
        "attention_span = 1  #only one attention update per weight update? Why is it so slow then (current settings approx 2.5 minutes per epoch)? Because batch ==1 probably.\n",
        "lr_attention = 5e-3\n",
        "# attention_span * lr_attention constant to have the same global update. The max was approx 20\n",
        "lr_weights = 1e-0\n",
        "weight_seed=0\n",
        "std_weights = 0.02\n",
        "\n",
        "train_network(attention_span, lr_attention, lr_weights, std_weights, weight_seed)   \n",
        "\n",
        "\n",
        "## NB QAGREL was compared with batch_size = 1. If you change the batch size you have to change also the learning rate! instead you used 1e-2, i.e. the same as I use for bs100. \n",
        "## NNB Too small validation set. Overestimates generalization capability of the model."
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HEB_T1_a0.005_w1.0_s0\n",
            "Layer Dense: [28, 28, 1] -> [1500], activation: <function relu at 0x7fc266b0d8c8>, flatten: True, dropout: 0.0%\n",
            "Layer Dense: [1500] -> [1000], activation: <function relu at 0x7fc266b0d8c8>, flatten: False, dropout: 0.0%\n",
            "Layer Dense: [1000] -> [500], activation: <function relu at 0x7fc266b0d8c8>, flatten: False, dropout: 0.0%\n",
            "Layer Dense: [500] -> [10], activation: <function identity at 0x7fc266d17b70>, flatten: False, dropout: 0.0%\n",
            "Epoch: 0 Time elapsed: 104.81: Training loss: 0.8871 Training accuracy: 68.95% Validation accuracy: 92.88%\n",
            "Epoch: 1 Time elapsed: 104.42: Training loss: 0.2045 Training accuracy: 92.95% Validation accuracy: 95.80%\n",
            "Epoch: 2 Time elapsed: 104.65: Training loss: 0.1396 Training accuracy: 94.75% Validation accuracy: 96.50%\n",
            "Epoch: 3 Time elapsed: 104.48: Training loss: 0.1086 Training accuracy: 95.69% Validation accuracy: 96.93%\n",
            "Epoch: 4 Time elapsed: 104.83: Training loss: 0.0890 Training accuracy: 96.25% Validation accuracy: 97.33%\n",
            "Epoch: 5 Time elapsed: 104.43: Training loss: 0.0761 Training accuracy: 96.53% Validation accuracy: 97.61%\n",
            "Epoch: 6 Time elapsed: 104.56: Training loss: 0.0656 Training accuracy: 96.90% Validation accuracy: 97.42%\n",
            "Epoch: 7 Time elapsed: 104.58: Training loss: 0.0570 Training accuracy: 97.29% Validation accuracy: 97.62%\n",
            "Epoch: 8 Time elapsed: 104.29: Training loss: 0.0509 Training accuracy: 97.31% Validation accuracy: 97.61%\n",
            "Epoch: 9 Time elapsed: 105.04: Training loss: 0.0458 Training accuracy: 97.59% Validation accuracy: 97.70%\n",
            "Epoch: 10 Time elapsed: 105.36: Training loss: 0.0414 Training accuracy: 97.62% Validation accuracy: 98.03%\n",
            "Epoch: 11 Time elapsed: 104.44: Training loss: 0.0379 Training accuracy: 97.76% Validation accuracy: 98.08%\n",
            "Epoch: 12 Time elapsed: 104.68: Training loss: 0.0349 Training accuracy: 97.91% Validation accuracy: 97.98%\n",
            "Epoch: 13 Time elapsed: 105.27: Training loss: 0.0327 Training accuracy: 98.01% Validation accuracy: 97.91%\n",
            "Epoch: 14 Time elapsed: 104.47: Training loss: 0.0297 Training accuracy: 98.04% Validation accuracy: 97.93%\n",
            "Epoch: 15 Time elapsed: 104.60: Training loss: 0.0284 Training accuracy: 97.97% Validation accuracy: 98.15%\n",
            "Epoch: 16 Time elapsed: 104.96: Training loss: 0.0273 Training accuracy: 98.07% Validation accuracy: 98.06%\n",
            "Epoch: 17 Time elapsed: 104.40: Training loss: 0.0269 Training accuracy: 98.07% Validation accuracy: 98.15%\n",
            "Epoch: 18 Time elapsed: 104.61: Training loss: 0.0248 Training accuracy: 98.05% Validation accuracy: 98.26%\n",
            "Epoch: 19 Time elapsed: 104.99: Training loss: 0.0224 Training accuracy: 98.24% Validation accuracy: 98.19%\n",
            "Epoch: 20 Time elapsed: 104.71: Training loss: 0.0228 Training accuracy: 98.14% Validation accuracy: 98.13%\n",
            "Epoch: 21 Time elapsed: 104.34: Training loss: 0.0217 Training accuracy: 98.22% Validation accuracy: 98.17%\n",
            "Epoch: 22 Time elapsed: 104.84: Training loss: 0.0203 Training accuracy: 98.25% Validation accuracy: 98.29%\n",
            "Epoch: 23 Time elapsed: 105.60: Training loss: 0.0199 Training accuracy: 98.22% Validation accuracy: 98.07%\n",
            "Epoch: 24 Time elapsed: 105.18: Training loss: 0.0192 Training accuracy: 98.15% Validation accuracy: 98.20%\n",
            "Epoch: 25 Time elapsed: 104.79: Training loss: 0.0184 Training accuracy: 98.21% Validation accuracy: 98.20%\n",
            "Epoch: 26 Time elapsed: 104.51: Training loss: 0.0180 Training accuracy: 98.23% Validation accuracy: 98.15%\n",
            "Epoch: 27 Time elapsed: 104.52: Training loss: 0.0173 Training accuracy: 98.22% Validation accuracy: 98.32%\n",
            "Epoch: 28 Time elapsed: 104.86: Training loss: 0.0175 Training accuracy: 98.18% Validation accuracy: 98.15%\n",
            "Epoch: 29 Time elapsed: 104.64: Training loss: 0.0168 Training accuracy: 98.27% Validation accuracy: 98.19%\n",
            "Epoch: 30 Time elapsed: 104.41: Training loss: 0.0162 Training accuracy: 98.30% Validation accuracy: 98.32%\n",
            "Epoch: 31 Time elapsed: 105.04: Training loss: 0.0162 Training accuracy: 98.27% Validation accuracy: 98.19%\n",
            "Epoch: 32 Time elapsed: 104.37: Training loss: 0.0156 Training accuracy: 98.38% Validation accuracy: 98.22%\n",
            "Epoch: 33 Time elapsed: 104.45: Training loss: 0.0152 Training accuracy: 98.20% Validation accuracy: 98.32%\n",
            "Epoch: 34 Time elapsed: 104.56: Training loss: 0.0156 Training accuracy: 98.22% Validation accuracy: 98.20%\n",
            "Epoch: 35 Time elapsed: 103.89: Training loss: 0.0145 Training accuracy: 98.26% Validation accuracy: 98.43%\n",
            "Epoch: 36 Time elapsed: 103.96: Training loss: 0.0147 Training accuracy: 98.28% Validation accuracy: 98.34%\n",
            "Epoch: 37 Time elapsed: 104.79: Training loss: 0.0143 Training accuracy: 98.30% Validation accuracy: 98.35%\n",
            "Epoch: 38 Time elapsed: 104.31: Training loss: 0.0135 Training accuracy: 98.34% Validation accuracy: 98.32%\n",
            "Epoch: 39 Time elapsed: 104.20: Training loss: 0.0134 Training accuracy: 98.41% Validation accuracy: 98.21%\n",
            "Epoch: 40 Time elapsed: 104.68: Training loss: 0.0156 Training accuracy: 98.16% Validation accuracy: 98.24%\n",
            "Epoch: 41 Time elapsed: 104.39: Training loss: 0.0131 Training accuracy: 98.30% Validation accuracy: 98.32%\n",
            "Epoch: 42 Time elapsed: 104.22: Training loss: 0.0128 Training accuracy: 98.29% Validation accuracy: 98.24%\n",
            "Epoch: 43 Time elapsed: 104.73: Training loss: 0.0127 Training accuracy: 98.37% Validation accuracy: 98.34%\n",
            "Epoch: 44 Time elapsed: 104.24: Training loss: 0.0131 Training accuracy: 98.31% Validation accuracy: 98.25%\n",
            "Epoch: 45 Time elapsed: 103.83: Training loss: 0.0126 Training accuracy: 98.29% Validation accuracy: 98.24%\n",
            "Epoch: 46 Time elapsed: 104.77: Training loss: 0.0116 Training accuracy: 98.33% Validation accuracy: 98.43%\n",
            "Epoch: 47 Time elapsed: 104.50: Training loss: 0.0121 Training accuracy: 98.35% Validation accuracy: 98.31%\n",
            "Epoch: 48 Time elapsed: 103.81: Training loss: 0.0117 Training accuracy: 98.29% Validation accuracy: 98.43%\n",
            "Epoch: 49 Time elapsed: 104.82: Training loss: 0.0116 Training accuracy: 98.37% Validation accuracy: 98.34%\n",
            "Epoch: 50 Time elapsed: 104.72: Training loss: 0.0113 Training accuracy: 98.38% Validation accuracy: 98.33%\n",
            "Epoch: 51 Time elapsed: 104.48: Training loss: 0.0115 Training accuracy: 98.33% Validation accuracy: 98.20%\n",
            "Epoch: 52 Time elapsed: 104.93: Training loss: 0.0111 Training accuracy: 98.27% Validation accuracy: 98.42%\n",
            "Epoch: 53 Time elapsed: 104.29: Training loss: 0.0109 Training accuracy: 98.35% Validation accuracy: 98.45%\n",
            "Epoch: 54 Time elapsed: 104.08: Training loss: 0.0111 Training accuracy: 98.34% Validation accuracy: 98.26%\n",
            "Epoch: 55 Time elapsed: 104.54: Training loss: 0.0109 Training accuracy: 98.45% Validation accuracy: 98.40%\n",
            "Epoch: 56 Time elapsed: 104.12: Training loss: 0.0109 Training accuracy: 98.38% Validation accuracy: 98.32%\n",
            "Epoch: 57 Time elapsed: 104.00: Training loss: 0.0107 Training accuracy: 98.35% Validation accuracy: 98.40%\n",
            "Epoch: 58 Time elapsed: 104.88: Training loss: 0.0107 Training accuracy: 98.37% Validation accuracy: 98.36%\n",
            "Epoch: 59 Time elapsed: 104.45: Training loss: 0.0108 Training accuracy: 98.45% Validation accuracy: 98.34%\n",
            "Epoch: 60 Time elapsed: 105.73: Training loss: 0.0102 Training accuracy: 98.33% Validation accuracy: 98.30%\n",
            "Epoch: 61 Time elapsed: 106.16: Training loss: 0.0110 Training accuracy: 98.43% Validation accuracy: 98.34%\n",
            "Epoch: 62 Time elapsed: 104.65: Training loss: 0.0109 Training accuracy: 98.29% Validation accuracy: 98.34%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-191-ad9f3db34727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mstd_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_span\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-190-a9c558e48a92>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(attention_span, lr_a, lr_w, w_init, s)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mcurr_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mcurr_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mrewards\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcurr_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIHY9jDNH4hP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}